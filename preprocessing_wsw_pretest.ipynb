{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>building_number</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>solar_radiation</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 01</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1047.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 02</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 03</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>953.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 04</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  building_number    date_time  temperature  rainfall  \\\n",
       "0  1_20220601 00                1  20220601 00         18.6       NaN   \n",
       "1  1_20220601 01                1  20220601 01         18.0       NaN   \n",
       "2  1_20220601 02                1  20220601 02         17.7       NaN   \n",
       "3  1_20220601 03                1  20220601 03         16.7       NaN   \n",
       "4  1_20220601 04                1  20220601 04         18.4       NaN   \n",
       "\n",
       "   windspeed  humidity  sunshine  solar_radiation  power_consumption  \n",
       "0        0.9      42.0       NaN              NaN            1085.28  \n",
       "1        1.1      45.0       NaN              NaN            1047.36  \n",
       "2        1.5      45.0       NaN              NaN             974.88  \n",
       "3        1.4      48.0       NaN              NaN             953.76  \n",
       "4        2.8      43.0       NaN              NaN             986.40  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import lightgbm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "t = time.strftime('%m%d-%H%M', time.localtime(time.time()))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(0) # Seed 고정\n",
    "#데이터 불러오기\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmw(df):\n",
    "    df = df.fillna(0)\n",
    "    date = pd.to_datetime(df.date_time)\n",
    "    df['hour'] = date.dt.hour\n",
    "    df['day'] = date.dt.weekday\n",
    "    df['month'] = date.dt.month\n",
    "    df['week'] = date.dt.isocalendar().week\n",
    "        \n",
    "    df['holiday'] = df.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "    df['date_time'] = df['date_time'].apply(lambda x : int(x[0:8]))\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 2) &(df['week'] == 22), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 0) &(df['week'] == 23), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 8) & (df['day'] == 0) &(df['week'] == 33), 'holiday')] = 1\n",
    "    \n",
    "    def CDH(xs):\n",
    "        ys = []\n",
    "        for i in range(len(xs)):\n",
    "            if i < 11:\n",
    "                ys.append(np.sum(xs[:(i+1)]-26))\n",
    "            else:\n",
    "                ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "        return np.array(ys)\n",
    "    cdhs = np.array([])\n",
    "    \n",
    "    for num in range(1,101,1):\n",
    "        temp = df[df['building_number'] == num]\n",
    "        cdh = CDH(temp['temperature'].values)\n",
    "        cdhs = np.concatenate([cdhs, cdh])\n",
    "    df['CDH'] = cdhs\n",
    "    ## https://dacon.io/competitions/official/235680/codeshare/2366?page=1&dtype=recent\n",
    "    df['sin_time'] = np.sin(2*np.pi*df.hour/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df.hour/24)\n",
    "    ## https://dacon.io/competitions/official/235736/codeshare/2743?page=1&dtype=recent\n",
    "    df['THI'] = 9/5*df['temperature'] - 0.55*(1-df['humidity']/100)*(9/5*df['humidity']-26)+32\n",
    "    return df\n",
    "\n",
    "dmw = dmw(df)\n",
    "\n",
    "esangch_95_1 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2), 'power_consumption']\n",
    "sum16 = esangch_95_1.sum()/12\n",
    "esangch_95_2 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2), 'power_consumption']\n",
    "sum17 = (esangch_95_2.sum()-0.36)/12\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum16\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum17\n",
    "dmw\n",
    "dmw.to_csv('./data/dmw_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 빌딩별로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = pd.DataFrame()\n",
    "pretest_df1 = pd.DataFrame()\n",
    "for i in range(1,101,1):\n",
    "    buff = dmw.loc[(dmw.building_number == i)] \n",
    "    train_df1 = pd.concat([train_df1, buff[:-168]])\n",
    "    pretest_df1 = pd.concat([pretest_df1, buff[-168:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outlier_index = {\n",
    "4: [1318],\n",
    "7: [442, 1578, 1579],\n",
    "11: [1300, 1301, 1493, 1658, 1665],\n",
    "17: list(range(1249, 1272)),\n",
    "22: [830],\n",
    "28: [1370],\n",
    "34: [1653],\n",
    "35: [1653, 1654],\n",
    "56: [184],\n",
    "58: list(range(810, 838)),\n",
    "70: list(range(1412, 1584)),\n",
    "75: [202] + list(range(343, 355)) + list(range(463, 496)) + [1433],\n",
    "91: [184],\n",
    "92: [1281],\n",
    "98: [1489],\n",
    "100: [185, 686]\n",
    "}\n",
    "\n",
    "\n",
    "def outlier(df,i):\n",
    "    df['outlier'] = 0\n",
    "    for k ,v in outlier_index.items():\n",
    "        if i == k:\n",
    "            df['outlier'] = df.index.isin(v).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Tw(Ta, RH):\n",
    "    term1 = Ta * np.arctan(0.151977 * (RH + 8.313659)**0.5)\n",
    "    term2 = np.arctan(Ta + RH)\n",
    "    term3 = np.arctan(RH - 1.67633)\n",
    "    term4 = 0.00391838 * (RH**1.5) * np.arctan(0.023101 * RH)\n",
    "    term5 = 4.686035\n",
    "    Tw = term1 + term2 - term3 + term4 - term5\n",
    "    return Tw\n",
    "\n",
    "def sensory(df):\n",
    "    ta = df['temperature']\n",
    "    rh = df['humidity']\n",
    "    tw = calculate_Tw(ta, rh)\n",
    "    df['sensory'] = -0.2442 + 0.55399*tw + 0.45535*df['temperature'] - 0.0022*(tw**2) + 0.00278*tw*df['temperature'] + 3.0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, target_df):\n",
    "    \n",
    "    filtered_df = target_df[target_df['outlier'] < 1]\n",
    "\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 평균 넣어주기\n",
    "    power_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 표준편차 넣어주기\n",
    "    power_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 평균 넣어주기\n",
    "    power_hour_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 표준편차 넣어주기\n",
    "    power_hour_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    #추가\n",
    "    #power_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour', 'day'], aggfunc = np.median).reset_index()\n",
    "    #power_hour_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour'], aggfunc = np.median).reset_index()\n",
    "    #######################################\n",
    "     # 병합을 위한 키 설정\n",
    "    merge_keys = ['hour', 'day']  \n",
    "    # 데이터프레임 병합\n",
    "    df = df.merge(power_mean[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_mean'))\n",
    "    df = df.merge(power_std[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_std'))\n",
    "    df = df.merge(power_hour_mean[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_mean'))\n",
    "    df = df.merge(power_hour_std[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_std'))\n",
    "    \n",
    "    #추가\n",
    "    #df = df.merge(power_median[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_median'))\n",
    "    #df = df.merge(power_hour_median[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_median'))\n",
    "    \n",
    "    df = df.rename(columns = {'power_consumption_day_hour_mean':'day_hour_mean','power_consumption_day_hour_std':'day_hour_std','power_consumption_hour_mean':'hour_mean','power_consumption_hour_std':'hour_std'})\n",
    "    #,'power_consumption_hour_mean':'hour_mean','power_consumption_hour_std':'hour_std'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train(df):\n",
    "    filtered_df = df[df['outlier'] < 1]\n",
    "    \n",
    "    grouped = filtered_df.groupby(['date_time'])\n",
    "    df['max_power'] = grouped['power_consumption'].transform(np.max)\n",
    "    df['min_power'] = grouped['power_consumption'].transform(np.min)\n",
    "    \n",
    "    grouped2 = df.groupby(['day'])\n",
    "    df['max_power'] = grouped2['max_power'].transform(np.mean)\n",
    "    df['min_power'] = grouped2['min_power'].transform(np.mean)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "    return df.drop(columns=['date_time'])\n",
    "\n",
    "def data_test(df, target_df):\n",
    "\n",
    "    grouped_train = target_df.groupby(['day'])\n",
    "    df['max_power'] = grouped_train['max_power'].transform(np.max)\n",
    "    df['min_power'] = grouped_train['min_power'].transform(np.max)\n",
    "   \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "\n",
    "    \n",
    "    \n",
    "    return df.drop(columns=['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_type(df):\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "    df['THI_cat'] = df['THI_cat'].astype('category')\n",
    "    \n",
    "    df['holiday'] = df['holiday'].astype('category')\n",
    "    df['Rain_cat'] = pd.cut(df['rainfall'], bins = [0,1,3,5,10,15,20,30,40,50,70,110],labels=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "    df['Rain_cat'] = df['Rain_cat'].cat.add_categories([0])\n",
    "    df.loc[((df['rainfall'] == 0), 'Rain_cat')] = 0\n",
    "    # test = df['day_hour_mean']\n",
    "    # min_val = np.min(test)\n",
    "    # max_val = np.max(test)\n",
    "    # df['day_hour_mean'] = (test-min_val)/(max_val-min_val)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "for i in range(1,101,1):\n",
    "    tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "    tr = tr.drop(columns=['index','building_number'])\n",
    "    te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "    te = te.drop(columns=['index','building_number'])\n",
    "    \n",
    "    outlier_train_df = outlier(tr,i)\n",
    "    outlier_pretest_df = outlier(te,i)\n",
    "    \n",
    "    #pr_train_df = preprocessing(outlier_train_df,outlier_train_df)\n",
    "    #pr_pretest_df = preprocessing(outlier_pretest_df,outlier_train_df)\n",
    "\n",
    "    #mm_train_df = data_train(pr_train_df)\n",
    "    #mm_pretest_df = data_test(pr_pretest_df, pr_train_df)\n",
    "    \n",
    "    mm_train_df = sensory(outlier_train_df)\n",
    "    mm_pretest_df = sensory(outlier_pretest_df)\n",
    "\n",
    "    mm_train_df = change_type(mm_train_df).drop(columns=['date_time'])\n",
    "    mm_pretest_df = change_type(mm_pretest_df).drop(columns=['date_time'])\n",
    "    \n",
    "    \n",
    "    mm_train_df.to_csv(f'./pretest/train_building{i}.csv',index =False)\n",
    "    mm_pretest_df.to_csv(f'./pretest/pretest_building{i}.csv',index =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "# pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "\n",
    "# i = \n",
    "# tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "# tr = tr.drop(columns=['index','building_number'])\n",
    "# te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "# te = te.drop(columns=['index','building_number'])\n",
    "\n",
    "# pr_train_df = preprocessing(tr,tr)\n",
    "# pr_pretest_df = preprocessing(te,tr)\n",
    "\n",
    "# mm_train_df = data_train(pr_train_df2)\n",
    "# mm_pretest_df = data_test(pr_pretest_df2, pr_train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   temperature        1872 non-null   float64\n",
      " 1   rainfall           1872 non-null   float64\n",
      " 2   windspeed          1872 non-null   float64\n",
      " 3   humidity           1872 non-null   float64\n",
      " 4   power_consumption  1872 non-null   float64\n",
      " 5   hour               1872 non-null   int64  \n",
      " 6   day                1872 non-null   int64  \n",
      " 7   month              1872 non-null   int64  \n",
      " 8   week               1872 non-null   int64  \n",
      " 9   holiday            1872 non-null   int64  \n",
      " 10  CDH                1872 non-null   float64\n",
      " 11  sin_time           1872 non-null   float64\n",
      " 12  cos_time           1872 non-null   float64\n",
      " 13  THI                1872 non-null   float64\n",
      " 14  outlier            1872 non-null   int64  \n",
      " 15  sensory            1872 non-null   float64\n",
      " 16  THI_cat            1872 non-null   int64  \n",
      " 17  Rain_cat           1872 non-null   int64  \n",
      "dtypes: float64(10), int64(8)\n",
      "memory usage: 263.4 KB\n"
     ]
    }
   ],
   "source": [
    "i = 75\n",
    "dd = pd.read_csv(f'./pretest/train_building{i}.csv')\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   temperature        168 non-null    float64\n",
      " 1   rainfall           168 non-null    float64\n",
      " 2   windspeed          168 non-null    float64\n",
      " 3   humidity           168 non-null    float64\n",
      " 4   power_consumption  168 non-null    float64\n",
      " 5   hour               168 non-null    int64  \n",
      " 6   day                168 non-null    int64  \n",
      " 7   month              168 non-null    int64  \n",
      " 8   week               168 non-null    int64  \n",
      " 9   holiday            168 non-null    int64  \n",
      " 10  CDH                168 non-null    float64\n",
      " 11  sin_time           168 non-null    float64\n",
      " 12  cos_time           168 non-null    float64\n",
      " 13  THI                168 non-null    float64\n",
      " 14  outlier            168 non-null    int64  \n",
      " 15  sensory            168 non-null    float64\n",
      " 16  THI_cat            168 non-null    int64  \n",
      " 17  Rain_cat           168 non-null    int64  \n",
      "dtypes: float64(10), int64(8)\n",
      "memory usage: 23.8 KB\n"
     ]
    }
   ],
   "source": [
    "i = 75\n",
    "dd = pd.read_csv(f'./pretest/pretest_building{i}.csv')\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test용\n",
    "# merged_train_df.to_csv(f'./data/train_split_wsw_{t}.csv')\n",
    "# merged_pretest_df.to_csv(f'./data/pretest_wsw_{t}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빌딩별로 csv생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train,test\n",
    "# train_df  = pd.read_csv((f'./data/train_split_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# pretest_df  = pd.read_csv((f'./data/pretest_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = pretest_df.loc[pretest_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./pretest/train_building{i}.csv')\n",
    "#     te.to_csv(f'./pretest/pretest_building{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #혹시 vaild를 나눠야 할수도있을때만 사용\n",
    "# train_df  = pd.read_csv((f'./split/train_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# test_df  = pd.read_csv((f'./split/test_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = test_df.loc[test_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./split/train_building{i}.csv')\n",
    "#     te.to_csv(f'./split/test_building{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
