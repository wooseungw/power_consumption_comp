{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>building_number</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>solar_radiation</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 01</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1047.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 02</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 03</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>953.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 04</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  building_number    date_time  temperature  rainfall  \\\n",
       "0  1_20220601 00                1  20220601 00         18.6       NaN   \n",
       "1  1_20220601 01                1  20220601 01         18.0       NaN   \n",
       "2  1_20220601 02                1  20220601 02         17.7       NaN   \n",
       "3  1_20220601 03                1  20220601 03         16.7       NaN   \n",
       "4  1_20220601 04                1  20220601 04         18.4       NaN   \n",
       "\n",
       "   windspeed  humidity  sunshine  solar_radiation  power_consumption  \n",
       "0        0.9      42.0       NaN              NaN            1085.28  \n",
       "1        1.1      45.0       NaN              NaN            1047.36  \n",
       "2        1.5      45.0       NaN              NaN             974.88  \n",
       "3        1.4      48.0       NaN              NaN             953.76  \n",
       "4        2.8      43.0       NaN              NaN             986.40  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import lightgbm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "t = time.strftime('%m%d-%H%M', time.localtime(time.time()))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(0) # Seed 고정\n",
    "#데이터 불러오기\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmw(df):\n",
    "    df = df.fillna(0)\n",
    "    date = pd.to_datetime(df.date_time)\n",
    "    df['hour'] = date.dt.hour\n",
    "    df['day'] = date.dt.weekday\n",
    "    df['month'] = date.dt.month\n",
    "    df['week'] = date.dt.isocalendar().week\n",
    "        \n",
    "    df['holiday'] = df.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "    df['date_time'] = df['date_time'].apply(lambda x : int(x[0:8]))\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 2) &(df['week'] == 22), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 0) &(df['week'] == 23), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 8) & (df['day'] == 0) &(df['week'] == 33), 'holiday')] = 1\n",
    "    \n",
    "    def CDH(xs):\n",
    "        ys = []\n",
    "        for i in range(len(xs)):\n",
    "            if i < 11:\n",
    "                ys.append(np.sum(xs[:(i+1)]-26))\n",
    "            else:\n",
    "                ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "        return np.array(ys)\n",
    "    cdhs = np.array([])\n",
    "    \n",
    "    for num in range(1,101,1):\n",
    "        temp = df[df['building_number'] == num]\n",
    "        cdh = CDH(temp['temperature'].values)\n",
    "        cdhs = np.concatenate([cdhs, cdh])\n",
    "    df['CDH'] = cdhs\n",
    "    ## https://dacon.io/competitions/official/235680/codeshare/2366?page=1&dtype=recent\n",
    "    df['sin_time'] = np.sin(2*np.pi*df.hour/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df.hour/24)\n",
    "    ## https://dacon.io/competitions/official/235736/codeshare/2743?page=1&dtype=recent\n",
    "    df['THI'] = 9/5*df['temperature'] - 0.55*(1-df['humidity']/100)*(9/5*df['humidity']-26)+32\n",
    "    return df\n",
    "\n",
    "dmw = dmw(df)\n",
    "\n",
    "esangch_95_1 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2), 'power_consumption']\n",
    "sum16 = esangch_95_1.sum()/12\n",
    "esangch_95_2 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2), 'power_consumption']\n",
    "sum17 = (esangch_95_2.sum()-0.36)/12\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum16\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum17\n",
    "dmw\n",
    "dmw.to_csv('./data/dmw_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 빌딩별로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = pd.DataFrame()\n",
    "pretest_df1 = pd.DataFrame()\n",
    "for i in range(1,101,1):\n",
    "    buff = dmw.loc[(dmw.building_number == i)] \n",
    "    train_df1 = pd.concat([train_df1, buff[:-168]])\n",
    "    pretest_df1 = pd.concat([pretest_df1, buff[-168:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outlier_index = {\n",
    "4: [1318],\n",
    "7: [442, 1578, 1579],\n",
    "11: [1300, 1301, 1493, 1658, 1665],\n",
    "17: list(range(1249, 1272)),\n",
    "22: [830],\n",
    "28: [1370],\n",
    "34: [1653],\n",
    "35: [1653, 1654],\n",
    "56: [184],\n",
    "58: list(range(810, 838)),\n",
    "70: list(range(1412, 1584)),\n",
    "75: [202] + list(range(343, 355)) + list(range(463, 496)) + [1433],\n",
    "91: [184],\n",
    "92: [1281],\n",
    "98: [1489],\n",
    "100: [185, 686]\n",
    "}\n",
    "\n",
    "\n",
    "def outlier(df,i):\n",
    "    df['outlier'] = 0\n",
    "    for k ,v in outlier_index.items():\n",
    "        if i == k:\n",
    "            df['outlier'] = df.index.isin(v).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, target_df):\n",
    "    \n",
    "    filtered_df = target_df[target_df['outlier'] < 1]\n",
    "\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 평균 넣어주기\n",
    "    power_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 표준편차 넣어주기\n",
    "    power_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 평균 넣어주기\n",
    "    power_hour_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 표준편차 넣어주기\n",
    "    power_hour_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    #추가\n",
    "    #power_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour', 'day'], aggfunc = np.median).reset_index()\n",
    "    #power_hour_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour'], aggfunc = np.median).reset_index()\n",
    "    #######################################\n",
    "     # 병합을 위한 키 설정\n",
    "    merge_keys = ['hour', 'day']  \n",
    "    # 데이터프레임 병합\n",
    "    df = df.merge(power_mean[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_mean'))\n",
    "    df = df.merge(power_std[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_std'))\n",
    "    df = df.merge(power_hour_mean[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_mean'))\n",
    "    df = df.merge(power_hour_std[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_std'))\n",
    "    \n",
    "    #추가\n",
    "    #df = df.merge(power_median[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_median'))\n",
    "    #df = df.merge(power_hour_median[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_median'))\n",
    "    \n",
    "    df = df.rename(columns = {'power_consumption_day_hour_mean':'day_hour_mean','power_consumption_day_hour_std':'day_hour_std','power_consumption_hour_mean':'hour_mean','power_consumption_hour_std':'hour_std'})\n",
    "    #,'power_consumption_hour_mean':'hour_mean','power_consumption_hour_std':'hour_std'\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train(df):\n",
    "    filtered_df = df[df['outlier'] < 1]\n",
    "    \n",
    "    grouped = filtered_df.groupby(['date_time'])\n",
    "    df['max_power'] = grouped['power_consumption'].transform(np.max)\n",
    "    df['min_power'] = grouped['power_consumption'].transform(np.min)\n",
    "    \n",
    "    grouped2 = df.groupby(['day'])\n",
    "    df['max_power'] = grouped2['max_power'].transform(np.mean)\n",
    "    df['min_power'] = grouped2['min_power'].transform(np.mean)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "    return df.drop(columns=['date_time'])\n",
    "\n",
    "def data_test(df, target_df):\n",
    "\n",
    "    grouped_train = target_df.groupby(['day'])\n",
    "    df['max_power'] = grouped_train['max_power'].transform(np.max)\n",
    "    df['min_power'] = grouped_train['min_power'].transform(np.max)\n",
    "   \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "\n",
    "    \n",
    "    \n",
    "    return df.drop(columns=['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_type(df):\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "    df['THI_cat'] = df['THI_cat'].astype('category')\n",
    "    \n",
    "    df['holiday'] = df['holiday'].astype('category')\n",
    "    \n",
    "    test = df['day_hour_mean']\n",
    "    min_val = np.min(test)\n",
    "    max_val = np.max(test)\n",
    "    df['day_hour_mean'] = (test-min_val)/(max_val-min_val)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['date_time'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m mm_train_df \u001b[39m=\u001b[39m data_train(pr_train_df)\n\u001b[0;32m     16\u001b[0m mm_pretest_df \u001b[39m=\u001b[39m data_test(pr_pretest_df, pr_train_df)\n\u001b[1;32m---> 19\u001b[0m mm_train_df \u001b[39m=\u001b[39m change_type(mm_train_df)\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mdate_time\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     20\u001b[0m mm_pretest_df \u001b[39m=\u001b[39m change_type(mm_pretest_df)\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdate_time\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m mm_train_df\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./pretest/train_building\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m,index \u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\poum\\Lib\\site-packages\\pandas\\core\\frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5266\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\poum\\Lib\\site-packages\\pandas\\core\\generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\poum\\Lib\\site-packages\\pandas\\core\\generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\poum\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['date_time'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "for i in range(1,101,1):\n",
    "    tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "    tr = tr.drop(columns=['index','building_number'])\n",
    "    te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "    te = te.drop(columns=['index','building_number'])\n",
    "    \n",
    "    outlier_train_df = outlier(tr,i)\n",
    "    outlier_pretest_df = outlier(te,i)\n",
    "    \n",
    "    pr_train_df = preprocessing(outlier_train_df,outlier_train_df)\n",
    "    pr_pretest_df = preprocessing(outlier_pretest_df,outlier_train_df)\n",
    "\n",
    "    mm_train_df = data_train(pr_train_df)\n",
    "    mm_pretest_df = data_test(pr_pretest_df, pr_train_df)\n",
    "    \n",
    "\n",
    "    mm_train_df = change_type(mm_train_df)\n",
    "    mm_pretest_df = change_type(mm_pretest_df)\n",
    "    \n",
    "    mm_train_df.to_csv(f'./pretest/train_building{i}.csv',index =False)\n",
    "    mm_pretest_df.to_csv(f'./pretest/pretest_building{i}.csv',index =False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "# pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "\n",
    "# i = \n",
    "# tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "# tr = tr.drop(columns=['index','building_number'])\n",
    "# te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "# te = te.drop(columns=['index','building_number'])\n",
    "\n",
    "# pr_train_df = preprocessing(tr,tr)\n",
    "# pr_pretest_df = preprocessing(te,tr)\n",
    "\n",
    "# mm_train_df = data_train(pr_train_df2)\n",
    "# mm_pretest_df = data_test(pr_pretest_df2, pr_train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   temperature        1872 non-null   float64\n",
      " 1   rainfall           1872 non-null   float64\n",
      " 2   windspeed          1872 non-null   float64\n",
      " 3   humidity           1872 non-null   float64\n",
      " 4   power_consumption  1872 non-null   float64\n",
      " 5   hour               1872 non-null   int64  \n",
      " 6   day                1872 non-null   int64  \n",
      " 7   month              1872 non-null   int64  \n",
      " 8   week               1872 non-null   int64  \n",
      " 9   holiday            1872 non-null   int64  \n",
      " 10  CDH                1872 non-null   float64\n",
      " 11  sin_time           1872 non-null   float64\n",
      " 12  cos_time           1872 non-null   float64\n",
      " 13  THI                1872 non-null   float64\n",
      " 14  outlier            1872 non-null   int64  \n",
      " 15  day_hour_mean      1872 non-null   float64\n",
      " 16  day_hour_std       1872 non-null   float64\n",
      " 17  THI_cat            1872 non-null   int64  \n",
      "dtypes: float64(11), int64(7)\n",
      "memory usage: 263.4 KB\n"
     ]
    }
   ],
   "source": [
    "i = 75\n",
    "dd = pd.read_csv(f'./pretest/train_building{i}.csv')\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 168 entries, 0 to 167\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   temperature        168 non-null    float64\n",
      " 1   rainfall           168 non-null    float64\n",
      " 2   windspeed          168 non-null    float64\n",
      " 3   humidity           168 non-null    float64\n",
      " 4   power_consumption  168 non-null    float64\n",
      " 5   hour               168 non-null    int64  \n",
      " 6   day                168 non-null    int64  \n",
      " 7   month              168 non-null    int64  \n",
      " 8   week               168 non-null    int64  \n",
      " 9   holiday            168 non-null    int64  \n",
      " 10  CDH                168 non-null    float64\n",
      " 11  sin_time           168 non-null    float64\n",
      " 12  cos_time           168 non-null    float64\n",
      " 13  THI                168 non-null    float64\n",
      " 14  outlier            168 non-null    int64  \n",
      " 15  day_hour_mean      168 non-null    float64\n",
      " 16  day_hour_std       168 non-null    float64\n",
      " 17  THI_cat            168 non-null    int64  \n",
      "dtypes: float64(11), int64(7)\n",
      "memory usage: 23.8 KB\n"
     ]
    }
   ],
   "source": [
    "i = 75\n",
    "dd = pd.read_csv(f'./pretest/pretest_building{i}.csv')\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test용\n",
    "# merged_train_df.to_csv(f'./data/train_split_wsw_{t}.csv')\n",
    "# merged_pretest_df.to_csv(f'./data/pretest_wsw_{t}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빌딩별로 csv생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train,test\n",
    "# train_df  = pd.read_csv((f'./data/train_split_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# pretest_df  = pd.read_csv((f'./data/pretest_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = pretest_df.loc[pretest_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./pretest/train_building{i}.csv')\n",
    "#     te.to_csv(f'./pretest/pretest_building{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #혹시 vaild를 나눠야 할수도있을때만 사용\n",
    "# train_df  = pd.read_csv((f'./split/train_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# test_df  = pd.read_csv((f'./split/test_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = test_df.loc[test_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./split/train_building{i}.csv')\n",
    "#     te.to_csv(f'./split/test_building{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
