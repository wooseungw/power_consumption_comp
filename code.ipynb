{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'X' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# 데이터 전처리\u001b[39;00m\n\u001b[0;32m     55\u001b[0m X_train, y_train \u001b[39m=\u001b[39m preprocess_data(df1_train, df2_train)\n\u001b[1;32m---> 56\u001b[0m X_test, y_test \u001b[39m=\u001b[39m preprocess_data(df1_test, df2_train, test \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# 테스트 데이터에는 '전력소비량(kWh)'가 없으므로 df2_train을 사용\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# 데이터셋 객체 생성\u001b[39;00m\n\u001b[0;32m     59\u001b[0m train_dataset \u001b[39m=\u001b[39m MyDataset(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(df1, df2, test)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m# 입력 데이터와 타겟 데이터 분리\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mif\u001b[39;00m test:\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n\u001b[0;32m     24\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39m전력소비량(kWh)\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'X' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "# 데이터 병합 및 전처리 함수\n",
    "def preprocess_data(df1, df2, test = False):\n",
    "    # 데이터 병합\n",
    "    df = pd.merge(df1, df2, on='건물번호', how='left')\n",
    "    \n",
    "    # 필요한 전처리 수행 (예: 결측치 처리, 데이터 형변환 등)\n",
    "    # 결측치 처리\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # 일시를 datetime 형태로 변환\n",
    "    df['일시'] = pd.to_datetime(df['일시'], format='%Y%m%d %H')\n",
    "\n",
    "    # 일시에서 시간을 추출하여 새로운 피처 생성\n",
    "    df['시간'] = df['일시'].dt.hour\n",
    "        \n",
    "    # 입력 데이터와 타겟 데이터 분리\n",
    "    if test:\n",
    "        return X\n",
    "    else:\n",
    "        X = df.drop('전력소비량(kWh)', axis=1)\n",
    "        y = df['전력소비량(kWh)']\n",
    "        return X, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 예측에 사용할 피처 선택\n",
    "features = ['건물번호', '기온(C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '일조(hr)', '일사(MJ/m2)', '연면적(m2)', '냉방면적(m2)', '시간']\n",
    "target = '전력소비량(kWh)'\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "df1_train = pd.read_csv('C:\\Workspace\\power_consumption_comp/data/train.csv')\n",
    "df2_train = pd.read_csv('C:\\Workspace\\power_consumption_comp\\data/building_info.csv')\n",
    "df1_test = pd.read_csv('C:\\Workspace\\power_consumption_comp\\data/test.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "X_train, y_train = preprocess_data(df1_train, df2_train)\n",
    "X_test, y_test = preprocess_data(df1_test, df2_train, test = True)  # 테스트 데이터에는 '전력소비량(kWh)'가 없으므로 df2_train을 사용\n",
    "\n",
    "# 데이터셋 객체 생성\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader 객체 생성\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)  # Swap time and channel dimensions for LSTM\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Use only the last output of the sequence\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = ConvLSTM(X)\n",
    "criterion = nn.MSELoss()  # For regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move the model to the device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # 100 epochs\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        for inputs, targets in valid_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {valid_loss/len(valid_loader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umpy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
