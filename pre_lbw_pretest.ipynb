{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>building_number</th>\n",
       "      <th>date_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>solar_radiation</th>\n",
       "      <th>power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20220601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 00</td>\n",
       "      <td>18.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1085.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20220601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 01</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1047.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20220601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 02</td>\n",
       "      <td>17.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20220601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 03</td>\n",
       "      <td>16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>953.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20220601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20220601 04</td>\n",
       "      <td>18.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>986.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  building_number    date_time  temperature  rainfall  \\\n",
       "0  1_20220601 00                1  20220601 00         18.6       NaN   \n",
       "1  1_20220601 01                1  20220601 01         18.0       NaN   \n",
       "2  1_20220601 02                1  20220601 02         17.7       NaN   \n",
       "3  1_20220601 03                1  20220601 03         16.7       NaN   \n",
       "4  1_20220601 04                1  20220601 04         18.4       NaN   \n",
       "\n",
       "   windspeed  humidity  sunshine  solar_radiation  power_consumption  \n",
       "0        0.9      42.0       NaN              NaN            1085.28  \n",
       "1        1.1      45.0       NaN              NaN            1047.36  \n",
       "2        1.5      45.0       NaN              NaN             974.88  \n",
       "3        1.4      48.0       NaN              NaN             953.76  \n",
       "4        2.8      43.0       NaN              NaN             986.40  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import lightgbm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "t = time.strftime('%m%d-%H%M', time.localtime(time.time()))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정\n",
    "#데이터 불러오기\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df = df.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmw(df):\n",
    "    df = df.fillna(0)\n",
    "    date = pd.to_datetime(df.date_time)\n",
    "    df['hour'] = date.dt.hour\n",
    "    df['day'] = date.dt.weekday\n",
    "    df['month'] = date.dt.month\n",
    "    df['week'] = date.dt.isocalendar().week\n",
    "        \n",
    "    df['holiday'] = df.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "    df['date_time'] = df['date_time'].apply(lambda x : int(x[0:8]))\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 2) &(df['week'] == 22), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 6) & (df['day'] == 0) &(df['week'] == 23), 'holiday')] = 1\n",
    "    df.loc[((df['month'] == 8) & (df['day'] == 0) &(df['week'] == 33), 'holiday')] = 1\n",
    "    \n",
    "    def CDH(xs):\n",
    "        ys = []\n",
    "        for i in range(len(xs)):\n",
    "            if i < 11:\n",
    "                ys.append(np.sum(xs[:(i+1)]-26))\n",
    "            else:\n",
    "                ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "        return np.array(ys)\n",
    "    cdhs = np.array([])\n",
    "    \n",
    "    for num in range(1,101,1):\n",
    "        temp = df[df['building_number'] == num]\n",
    "        cdh = CDH(temp['temperature'].values)\n",
    "        cdhs = np.concatenate([cdhs, cdh])\n",
    "    df['CDH'] = cdhs\n",
    "    ## https://dacon.io/competitions/official/235680/codeshare/2366?page=1&dtype=recent\n",
    "    df['sin_time'] = np.sin(2*np.pi*df.hour/24)\n",
    "    df['cos_time'] = np.cos(2*np.pi*df.hour/24)\n",
    "    ## https://dacon.io/competitions/official/235736/codeshare/2743?page=1&dtype=recent\n",
    "    df['THI'] = 9/5*df['temperature'] - 0.55*(1-df['humidity']/100)*(9/5*df['humidity']-26)+32\n",
    "    return df\n",
    "\n",
    "dmw = dmw(df)\n",
    "\n",
    "esangch_95_1 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2), 'power_consumption']\n",
    "sum16 = esangch_95_1.sum()/12\n",
    "esangch_95_2 = dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2), 'power_consumption']\n",
    "sum17 = (esangch_95_2.sum()-0.36)/12\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 16)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum16\n",
    "dmw.loc[(dmw.building_number == 95)&(dmw.hour == 17)&(dmw.day == 2)&(dmw.month == 7)&(dmw.week == 30), 'power_consumption'] = sum17\n",
    "dmw\n",
    "dmw.to_csv('./data/dmw_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1 = pd.DataFrame()\n",
    "pretest_df1 = pd.DataFrame()\n",
    "for i in range(1,101,1):\n",
    "    buff = dmw.loc[(dmw.building_number == i)] \n",
    "    train_df1 = pd.concat([train_df1, buff[:-168]])\n",
    "    pretest_df1 = pd.concat([pretest_df1, buff[-168:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 빌딩별로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, target_df):\n",
    "    # power_consumption의 하위 5% 값을 계산\n",
    "    threshold = target_df['power_consumption'].quantile(0.00)\n",
    "\n",
    "    # 하위 5% 값을 제외한 데이터만 필터링\n",
    "    filtered_df = target_df[target_df['power_consumption'] > threshold]\n",
    "\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 평균 넣어주기\n",
    "    power_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별, 요일별, 전력시간별 소비량 표준편차 넣어주기\n",
    "    power_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour', 'day'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 평균 넣어주기\n",
    "    power_hour_mean = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.mean).reset_index()\n",
    "    #######################################\n",
    "    ## 건물별 시간별 전력소비량 표준편차 넣어주기\n",
    "    power_hour_std = pd.pivot_table(filtered_df, values = 'power_consumption', index = ['hour'], aggfunc = np.std).reset_index()\n",
    "    #######################################\n",
    "    #추가\n",
    "    #power_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour', 'day'], aggfunc = np.median).reset_index()\n",
    "    #power_hour_median = pd.pivot_table(merged_train_df1, values = 'power_consumption', index = ['building_number', 'hour'], aggfunc = np.median).reset_index()\n",
    "    #######################################\n",
    "     # 병합을 위한 키 설정\n",
    "    merge_keys = ['hour', 'day']  \n",
    "    # 데이터프레임 병합\n",
    "    df = df.merge(power_mean[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_mean'))\n",
    "    df = df.merge(power_std[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_std'))\n",
    "    df = df.merge(power_hour_mean[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_mean'))\n",
    "    df = df.merge(power_hour_std[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_std'))\n",
    "    \n",
    "    #추가\n",
    "    #df = df.merge(power_median[merge_keys + ['power_consumption']], on=merge_keys, how='left', suffixes=('', '_day_hour_median'))\n",
    "    #df = df.merge(power_hour_median[merge_keys[:-1] + ['power_consumption']], on=merge_keys[:-1], how='left', suffixes=('', '_hour_median'))\n",
    "    \n",
    "    df = df.rename(columns = {'power_consumption_day_hour_mean':'day_hour_mean','power_consumption_day_hour_std':'day_hour_std','power_consumption_hour_mean':'hour_mean','power_consumption_hour_std':'hour_std'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_train(df):\n",
    "    \n",
    "    grouped = df.groupby(['date_time'])\n",
    "    df['max_power'] = grouped['power_consumption'].transform(np.max)\n",
    "    df['min_power'] = grouped['power_consumption'].transform(np.min)\n",
    "    \n",
    "    grouped2 = df.groupby(['day'])\n",
    "    df['max_power'] = grouped2['max_power'].transform(np.mean)\n",
    "    df['min_power'] = grouped2['min_power'].transform(np.mean)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "    return df.drop(columns=['date_time'])\n",
    "\n",
    "def data_test(df, target_df):\n",
    "    grouped_train = target_df.groupby(['day'])\n",
    "    max_power = grouped_train['max_power'].median()\n",
    "    min_power = grouped_train['min_power'].median()\n",
    "    max_power_df = max_power.reset_index()\n",
    "    min_power_df = min_power.reset_index()\n",
    "\n",
    "    # 테스트 데이터에 max_power_median와 min_power_median을 추가\n",
    "    df = pd.merge(df, max_power_df, on=['day'])\n",
    "    df = pd.merge(df, min_power_df, on=['day'])\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df = df.fillna(0)\n",
    "    df['THI_cat'] = pd.cut(df['THI'], bins = [0,68,75,80,200],labels=[1,2,3,4])\n",
    "\n",
    "    \n",
    "    \n",
    "    return df.drop(columns=['date_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_type(df):\n",
    "    df['THI_cat'] = df['THI_cat'].astype('category')\n",
    "    df['hour'] = df['hour'].astype('category')\n",
    "    df['holiday'] = df['holiday'].astype('category')\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hoilday'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\poum\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\poum\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\poum\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hoilday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m mm_train_df \u001b[39m=\u001b[39m data_train(pr_train_df)\n\u001b[0;32m     13\u001b[0m mm_pretest_df \u001b[39m=\u001b[39m data_test(pr_pretest_df, pr_train_df)\n\u001b[1;32m---> 16\u001b[0m mm_train_df \u001b[39m=\u001b[39m change_type(mm_train_df)\n\u001b[0;32m     17\u001b[0m mm_pretest_df \u001b[39m=\u001b[39m change_type(mm_pretest_df)\n\u001b[0;32m     19\u001b[0m mm_train_df\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./pretest/train_building\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m,index \u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[115], line 4\u001b[0m, in \u001b[0;36mchange_type\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mTHI_cat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mTHI_cat\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mhour\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mhoilday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mhoilday\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\poum\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\poum\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hoilday'"
     ]
    }
   ],
   "source": [
    "train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "for i in range(1,101,1):\n",
    "    tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "    tr = tr.drop(columns=['index','building_number'])\n",
    "    te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "    te = te.drop(columns=['index','building_number'])\n",
    "    \n",
    "    pr_train_df = preprocessing(tr,tr)\n",
    "    pr_pretest_df = preprocessing(te,tr)\n",
    "    \n",
    "    mm_train_df = data_train(pr_train_df)\n",
    "    mm_pretest_df = data_test(pr_pretest_df, pr_train_df)\n",
    "    \n",
    "\n",
    "    mm_train_df = change_type(mm_train_df)\n",
    "    mm_pretest_df = change_type(mm_pretest_df)\n",
    "    \n",
    "    mm_train_df.to_csv(f'./pretest/train_building{i}.csv',index =False)\n",
    "    mm_pretest_df.to_csv(f'./pretest/pretest_building{i}.csv',index =False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_first = train_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "# pretest_first = pretest_df1.drop(columns=['num_date_time','sunshine','solar_radiation'])\n",
    "\n",
    "# i = \n",
    "# tr = train_first.loc[train_first.building_number==i].reset_index()\n",
    "# tr = tr.drop(columns=['index','building_number'])\n",
    "# te = pretest_first.loc[pretest_first.building_number==i].reset_index()\n",
    "# te = te.drop(columns=['index','building_number'])\n",
    "\n",
    "# pr_train_df = preprocessing(tr,tr)\n",
    "# pr_pretest_df = preprocessing(te,tr)\n",
    "\n",
    "# mm_train_df = data_train(pr_train_df2)\n",
    "# mm_pretest_df = data_test(pr_pretest_df2, pr_train_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1872 entries, 0 to 1871\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   temperature        1872 non-null   float64\n",
      " 1   rainfall           1872 non-null   float64\n",
      " 2   windspeed          1872 non-null   float64\n",
      " 3   humidity           1872 non-null   float64\n",
      " 4   power_consumption  1872 non-null   float64\n",
      " 5   hour               1872 non-null   int64  \n",
      " 6   day                1872 non-null   int64  \n",
      " 7   month              1872 non-null   int64  \n",
      " 8   week               1872 non-null   int64  \n",
      " 9   holiday            1872 non-null   int64  \n",
      " 10  CDH                1872 non-null   float64\n",
      " 11  sin_time           1872 non-null   float64\n",
      " 12  cos_time           1872 non-null   float64\n",
      " 13  THI                1872 non-null   float64\n",
      " 14  day_hour_mean      1872 non-null   float64\n",
      " 15  day_hour_std       1872 non-null   float64\n",
      " 16  hour_mean          1872 non-null   float64\n",
      " 17  hour_std           1872 non-null   float64\n",
      " 18  max_power          1872 non-null   float64\n",
      " 19  min_power          1872 non-null   float64\n",
      " 20  THI_cat            1872 non-null   int64  \n",
      "dtypes: float64(15), int64(6)\n",
      "memory usage: 307.3 KB\n"
     ]
    }
   ],
   "source": [
    "i = 75\n",
    "dd = pd.read_csv(f'./pretest/train_building{i}.csv')\n",
    "dd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 75\n",
    "# dd = pd.read_csv(f'./pretest/train_building{i}.csv')\n",
    "# dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, pretest 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test용\n",
    "# merged_train_df.to_csv(f'./data/train_split_wsw_{t}.csv')\n",
    "# merged_pretest_df.to_csv(f'./data/pretest_wsw_{t}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빌딩별로 csv생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train,test\n",
    "# train_df  = pd.read_csv((f'./data/train_split_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# pretest_df  = pd.read_csv((f'./data/pretest_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = pretest_df.loc[pretest_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./pretest/train_building{i}.csv')\n",
    "#     te.to_csv(f'./pretest/pretest_building{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #혹시 vaild를 나눠야 할수도있을때만 사용\n",
    "# train_df  = pd.read_csv((f'./split/train_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# test_df  = pd.read_csv((f'./split/test_fianl_wsw_{t}.csv')).drop(columns='Unnamed: 0')\n",
    "# for i in range(1,101,1):\n",
    "#     tr = train_df.loc[train_df.building_number==i].reset_index()\n",
    "#     tr = tr.drop(columns=['index'])\n",
    "#     te = test_df.loc[test_df.building_number==i].reset_index()\n",
    "#     te = te.drop(columns=['index'])\n",
    "#     tr.to_csv(f'./split/train_building{i}.csv')\n",
    "#     te.to_csv(f'./split/test_building{i}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
